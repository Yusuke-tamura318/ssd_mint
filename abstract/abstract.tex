% TEX STUDIO MAGIC-COMMAND
% !TeX document-id = {21ffa6e2-6c8f-4532-897c-386dc477f19a}
% !TeX root = abstract.tex
% !TeX encoding = utf8
% !TeX TXS-program:compile = lualatex -file-line-error -synctex=1 -interaction=nonstopmode -halt-on-error %.tex
% !TeX TXS-program:quick = txs:///compile | txs:///view-pdf-internal --embedded
%%% TeXのファイル名を変えたら ↑ も変えましょう



%%%-------------------------------------------------------------------------
%%% PD3予稿集テンプレート （main.tex）
%%% 作成： 金沢工大・情報工学科・鷹合研究室(2022,01/12)
%%%-------------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                               テーマ，著者情報をここに書き込んでください
%ここから ------------------------------------------------------------------

%%% テーマ番号
\def\THEMEID{1EP001}

%%% タイトル
\def\TITLEJP{機械学習用いた電車の車両タイプの判別システムの開発}
\def\TITLEEN{Development of a train car type identification system using machine learning}
\def\CENTERADJ{3.3} % ここを書き換えて，表紙の「プロジェクトテーマ」という文字列がセル中心になるよう調整してください

%%% 教員名
\def\PROFNAME{鷹合 大輔 准教授}

%%% アブストラクト（英文で書く）
% 最低：100ワード，最大：300ワード前後
% 英文部分については，句読点は半角にすること．つまり", "か". "を使う
\def\ABSTRACT{
Describe about 5 lines of abstract in English here. Describe about 5 lines of abstract in English here. Describe about 5 lines of abstract in English here. Describe about 5 lines of abstract in English here. Describe about 5 lines of abstract in English here. Describe about 5 lines of abstract in English here. 
\textbf{（何が問題で，それをどんな手法で取り組んで，どういう結果であったかなどを英語で要約して下さい）}
 Describe about 5 lines of abstract in English here. Describe about 5 lines of abstract in English here. Describe about 5 lines of abstract in English here.
}

%%% キーワード(5個まで)
\def\KEYWORDS{YOLO，Machine Learning，Qwerty3，Qwerty4，Qwerty5}

%%% 著者リスト
\def\AUTHORS{
\begin{minipage}{13.5cm}
~\hfill 4EP1-68~野崎 悠渡(NOZAKI Yuto)      ~~~~~ 4EP5-11~田村 優祐(TAMURA Yusuke) \hfill~
\end{minipage}
}

\newcommand{\red}[1]{\textcolor{red}{#1}}


% テーマ，著者情報ここまで -----------------------------------------------------


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                本文


\documentclass{tkglabs}

\usepackage{caption}

\begin{document}
\maketitle
\begin{multicols*}{2} % *アスタ付きだとページのバランシングを無効にできる
%本文ここから ------------------------------------------------------------------



\section{はじめに}
%背景や目的をここに書いてください．
電車の車両タイプはJRの在来線だけでも100種類近く存在している．
多くの人は電車を見て電車だと認識することは可能だが，その電車の車両タイプまでを判断できる人は少ない．
電車についての知識がある人は一目見るだけでその電車の車両タイプを判断できるが，大多数の人は似ている電車の車両タイプを判断することが難しい.本プロジェクトでは簡単に画像や動画に写っている車両タイプが何なのかを判別できるシステムを開発する．

%\section{関連研究？現存するサービスについて？これいる？？}
%先行事例と本システムの独自性
%googleがgoogleレンズというサービスを提供している．これは，画像に写っている物体と同じものが写っているウェブサイトをまとめて表示するサービスである．このサービスの問題点は３つある．
%\begin{itemize}
%	\item 一枚の画像に複数の物体が写り込んでいると判別結果が正確ではなくなる．
%	\item 提示されたウェブサイトから詳細を確認しなければならない．
%	\item 動画から物体を判別することができないこと
%\end{itemize}

\section{システム概要}
開発するシステムの概要を図 \ref{abc}に示す．
\begin{figure} % 小さな図
	\label{abc}
	\centering
	\includegraphics[width=\linewidth]{obj/system.pdf}
	\figcap{後で変える}{System Overview}{abc}
\end{figure}

\section{判別モデルの開発の流れ}
電車が写っている画像を集めて，データセットを作成し，学習をするという流れで判別モデルを開発する．

\subsection{データ収集}
	YouTubeで特定の電車のみが映っている１〜３種類の動画を保存して，指定した枚数のランダムなフレームを保存する．保存した画像を識別して，	電車が映っている画像だけを保存する．
	動画ごとに電車が写っている時間が異なるため，集めた画像は車両タイプごとに異なる．
	%各車両タイプが名前になっているディレクトリに保存する．
	各車両タイプの保存枚数を図\ref{fig:chart}に示す．
	
	% TODO: \usepackage{graphicx} required
	\begin{figure}
		\centering
		\includegraphics[width=\linewidth]{obj/chart.pdf}
		\figcap{各車両タイプの保存枚数}{Number of images saved by vehicle type}{fig:chart}
%		\label{fig:chart}
	\end{figure}
\subsection{データセットの作成}
本プロジェクトで作成するモデルは識別モデル，分類モデルの二種類である．%データセットのディレクトリ構造が識別用と分類用で異なるので，それぞれのデータセットを作成した．識別モデルには画像のアノテーション情報も必要なので，アノテーションを行い，識別モデル用のデータセットを作成した．
分類モデルのデータセット内の画像をアノテーションして識別モデル用のデータセットを作成した．
様々なウェブサイトから手作業で１７種類の各車両の画像を１０枚ずつ集めて，テストデータセットも作成した．


\subsubsection{分類とは}
%画像には何が写っているのかを判断することを分類という．一枚の画像に一つの物体が写っている場合に分類ができる．
分類はデータやオブジェクトを異なるクラスやカテゴリに分けるプロセスを指す．画像の分類とは，画像が特定のカテゴリやクラスに属するかどうかを判別する作業である．例えば，画像に写っているのが猫か犬か，車か飛行機かなどのクラスに分類することがある．
\subsubsection{識別とは}
識別とは画像のどこに何が写っているのかを判断するプロセスを指す．１枚の画像に複数の物体が写っていても識別はできる．

\subsubsection{アノテーションとは}
%https://www.dir.co.jp/world/entry/solution/annotation
アノテーションとは、機械学習の分類の一つである教師あり学習において,分析対象データにラベルを付与するプロセスである.画像にバウンディングボックスと呼ばれる四角形を描画しクラス番号を指定する．バウンディングボックスを描画することでその画像に写っている物体の座標情報を取得することができる．クラス番号とは，判別したいものリストを作成し，画像に写っている物体に対応した，リストのインデックスのことである．アノテーションをした結果は，識別モデルの学習時に使用する．
%\subsubsection{分類モデル}
%分類モデルのデータセットは，分類したいものの画像をそれぞれの車両タイプの名前のディレクトリに保存する．

%\subsubsection{識別モデル}
%識別モデルのデータセットは，学習用とテスト用の２種類のディレクトリのそれぞれに画像と画像のアノテーション情報が記載されているテキストファイルを保存する．画像ファイルとそのアノテーション情報のテキストファイルはファイル名を統一する必要がある．\\
%どんなふうにアノテーションをしたのか説明が必要？\\
%アノテーション情報には，クラス番号と画像で物体が写っている部分の座標情報が必要である．
%本プロジェクトにおける識別モデルのクラス番号は，リスト形式で識別したい車両タイプを定義した，それぞれの車両タイプのインデックスとした


\subsection{モデルの学習}
%本プロジェクトでは\\
YOLOv8を用いてモデルを作成した．
\subsubsection{YOLOv8の概要}
YOLOとはYou Only Look Onceの略で，人間のように一目見るだけで物体検出ができることを指している．データセットを作成し学習させることで，任意の物体のみ検出させることが可能である．
YOLOv8はYOLOシリーズの最新バージョンであり，ディープラーニングとコンピュータビジョンの最先端の進歩に基づいており，速度と精度の麺で比類のない性能を提供している．
%https://docs.ultralytics.com/ja/ 参照


\subsubsection{学習の実行}
学習を進めると徐々に性能が上がっていき性能が向上しなくなると学習が途中で中断される．
学習は中断されるまで続けたため，学習回数はモデルによって差がある．

\subsection{モデルの使い方}
識別モデルと分類モデルをどのように使えば結果が出力されるのかを説明する．pythonのコードを貼り付ける？
田村のパートに記載してもいいかもしれない
\section{作成したモデルの評価}
%\subsection{モデルの性能評価指標}
%本プロジェクトで作成する分類モデルは混合行列から性能の評価を行う．混合行列とは実際のデータと予測データを比較するためのもので，正しくラベル設定ができているのか，及び予測の精確度を把握することができる．

\subsection{分類モデルの性能評価}
作成した分類モデルを用いてテストデータセットの分類を行った結果を図\ref{fig:classifyresults}に示す.
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{obj/classify_results.pdf}
	\figcap{性能評価}{seinouhyouka}{def}
	\label{fig:classifyresults}
\end{figure}

\subsection{識別モデルの性能評価}
%１７種類の車両タイプの画像をそれぞれ１０枚ずつ集めテストデータを作成し識別を行った．識別の結果を表\ref{detection}に示す．
%captionを追加するとエラーが発生してしまう
作成した識別モデルを用いてテストデータセットの識別を行った結果を図\ref{fig:chartdet}に示す．
識別失敗とは間違った車両タイプだと判断していることを指し，識別不能とはどの車両タイプにも当てはまらないと判断していることを指す．
% TODO: \usepackage{graphicx} required
\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{obj/chartDET.pdf}
	\figcap{テストデータ識別結果}{ababefn}{}
	\label{fig:chartdet}
\end{figure}





\section{考察}
正解率は電車によって異なることがわかる．特に外見が似ている電車だと，誤判別していることが多かった．%データセットの画質を落とすと誤判別が増えた．特に誤分類が多かった三種類の電車の画質を上げても結果はあまり変わらなかった．

%限られたストレージでは，データセットの画質を変化させて判別結果を向上させることは難しいと考えられる．SSDの容量に制限がない場合，大量の高画質のデータでデータセットを作成することで判別結果が改善される可能性があると考えられる．
各車両タイプの画像の枚数に差があったことが判別結果に影響を与えていると考えられる．
画像の枚数が少ない車両タイプの判別結果が必ず悪くはならなかった．
画像の枚数が判別結果に影響を与えるのではなく，車体の特徴が鮮明に写っている画像の枚数が判別結果に影響を与えると考えられる．データセットとして質の悪い画像を大量に集めるのではなく，車体の特徴が鮮明に写っている画像を車両タイプごとに集める必要があったと考えられる．\\


------------------ここまで野崎------------------\\
------------------ここから田村------------------\\
\section{システムについて} 

\subsection{システムの動作要件} 本システムでは，ノートパソコンにLinuxサーバのセットアップを行い，サーバとして使用した． ネットワークは，学内の固定IPを割り当ててもらい，学内ネットワークを使用した． 
サーバのスペックは以下の通りである．
\subsubsection{サーバのスペック} 
\begin{itemize} 
	\item OS: Ubuntu 22.04.3 LTS 
	\item メモリ: 4GB 
	\item CPU: Intel® Core(™) i7 
	\item GPU: NVIDIA GeForce GTX 470M \item HDD: 80GB 
\end{itemize}
\subsection{システムの開発環境} 本システムの開発には，以下の言語やツールを使用した．
\subsubsection{使用言語} 
\begin{itemize} 
	\item フロントエンド: 
	\begin{itemize} 
		\item html 
		\item JavaScript 
		\item css 
	\end{itemize} 
	\item バックエンド: 
	\begin{itemize} 
		\item JavaScript (Node.js) 
		\item Python 
	\end{itemize} 
\end{itemize}
\subsubsection{使用ツール} 
\begin{itemize} 
	\item エディタ: VSCode 
	\item ブラウザ: Google Chrome 119 
\end{itemize}

\subsection{システムの機能詳細} 本システムは，以下の3つの機能を提供する．
\subsubsection{電車の画像の分類} この機能では，ユーザがブラウザからアップロードした画像に含まれる電車の種類を分類する． 分類の結果，最も可能性が高いものをHTMLページに出力する．
\subsubsection{電車の画像の識別} この機能では，ユーザがブラウザからアップロードした画像に含まれる電車の位置と種類を識別する．  識別の結果，バウンディングボックスが追加された画像をHTMLページに表示する．
\subsubsection{電車の動画の識別} この機能では，ユーザがブラウザからアップロードした動画に含まれる電車の位置と種類を識別する． 識別の結果，バウンディングボックスが追加された動画をHTMLページに表示する．


\section{システムの速度検証}
画像・動画の解像度、各機能ごとの応答速度（解像度の調整が困難なためスマホのサイズでの検証にはしない）
（GPUで動作した際にはGPU固定）
GPUマシンが動作した場合、解像度一定で、各機能のCPU,GPU速度を検証
\subsection{システムの考察(GPU動作時)（仮）}
GPUを使用したときとCPUを使用したときでは動作の速度が大きく異なることが分かる。また、入力された画像や動画の解像度によっても速度が異なることが分かった。
\subsection{システムの考察(GPU非動作時)（仮）}
入力された画像や動画の解像度によっても速度が異なることが分かった。
\section{システムの考察}


------------------ここまで田村------------------\\

\section{まとめ}



%% 参考文献（必要に応じて追加）
\begin{thebibliography}{99}
%\bibitem{jp2k1} 織田 信長, 明智 光秀, "JPEG2000画像符号化システムにおける係数ビットモデリングと適応算術符号化，"Journal of signal processing(基礎シリーズ), vol.7, no.4, pp.257-266, July 2003.
%\bibitem{sdkguide}Parrot, "AR.Drone Developer Guide SDK 2.0"
%\bibitem{bk1} "金沢の暮らし", \url{http://www.kanazawa-it.ac.jp}
%\bibitem{bk2} 山田 太郎, "金沢の一人暮らし", トンチンカン出版, 2016.
\bibitem{bk0}"Ultralytics YOLOv8 ドキュメント",\url{https://docs.ultralytics.com/ja}
\bibitem{bk1}"アノテーションとは - 定義と重要性，必要な準備や注意点を解説",\url{https://www.dir.co.jp/world/entry/solution/annotation}
\end{thebibliography}

%\noindent\textbf{本プロジェクトに関する業績} % 学部
% \noindent\textbf{本研究に関する業績} % 院生の場合
%\begin{enumerate}[label=\arabic*),leftmargin=2.25\zw]
%\item 鈴木 大志 , 鷹合 大輔 , 中沢 実，"AutoVCを用いたゼロショットリアルタイム声質変換手法の提案"，2021-DPS-189(5), 1-6 (2021-12-13) , 2188-8906．
%\end{enumerate}

% 本文ここまで ------------------------------------------------------------------
\end{multicols*} 
\end{document}

